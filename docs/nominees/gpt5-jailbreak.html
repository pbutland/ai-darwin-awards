<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- Basic Meta -->
  <title>GPT-5 Jailbreak - “One Hour Security Record” - 2025 AI Darwin Award Nominee</title>
  <meta name="description" content="OpenAI launched GPT-5 with great fanfare about enhanced reasoning capabilities and improved safety alignment. The company presumably spent months developing sop">
  <meta name="robots" content="index, follow">
  <meta http-equiv="Content-Security-Policy" content="default-src 'self'; img-src 'self' https:; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline'; object-src 'none'; base-uri 'self'; form-action 'self';">

  <link rel="canonical" href="https://aidarwinawards.org/nominees/gpt5-jailbreak.html">
  <link rel="stylesheet" href="../styles/base.css">
  <link rel="stylesheet" href="../styles/nominees.css">
  <link rel="stylesheet" href="../styles/toast.css">

  <!-- Open Graph (Facebook, LinkedIn) -->
  <meta property="og:title" content="GPT-5 Jailbreak - “One Hour Security Record” - 2025 AI Darwin Award">
  <meta property="og:description" content="OpenAI launched GPT-5 with great fanfare about enhanced reasoning capabilities and improved safety alignment. The company presumably spent months developing sop">
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://aidarwinawards.org/nominees/gpt5-jailbreak.html">
  <meta property="og:site_name" content="AI Darwin Awards">
  <meta property="og:image" content="https://aidarwinawards.org/images/aidarwinawards-banner.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="GPT-5 Jailbreak - “One Hour Security Record”">

  <!-- Twitter Cards -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="GPT-5 Jailbreak - “One Hour Security Record” - 2025 AI Darwin Award">
  <meta name="twitter:description" content="OpenAI launched GPT-5 with great fanfare about enhanced reasoning capabilities and improved safety alignment. The company presumably spent months developing sop">
  <meta name="twitter:image" content="https://aidarwinawards.org/images/aidarwinawards-banner.png">
  <meta name="twitter:image:alt" content="GPT-5 Jailbreak - “One Hour Security Record”">
  <meta name="twitter:site" content="@aidarwinawards">

  <!-- Article-specific meta -->
  <meta property="article:author" content="AI Darwin Awards">
  <meta property="article:published_time" content="2025-07-01T00:00:00Z">
  <meta property="article:section" content="AI Failures">
  <meta property="article:tag" content="AI, Machine Learning, Technology Failures">

  <!-- Optional JSON-LD for richer snippets -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "headline": "GPT-5 Jailbreak - “One Hour Security Record”",
    "description": "OpenAI launched GPT-5 with great fanfare about enhanced reasoning capabilities and improved safety alignment. The company presumably spent months developing sop",
    "author": { "@type": "Organization", "name": "AI Darwin Awards" },
    "datePublished": "2025-07-01",
    "mainEntityOfPage": "https://aidarwinawards.org/nominees/gpt5-jailbreak.html",
    "breadcrumb": {
      "@type": "BreadcrumbList",
      "itemListElement": [
        {
          "@type": "ListItem",
          "position": 1,
          "name": "Home",
          "item": "https://aidarwinawards.org/"
        },
        {
          "@type": "ListItem",
          "position": 2,
          "name": "2025 Nominees",
          "item": "https://aidarwinawards.org/nominees-2025.html"
        },
        {
          "@type": "ListItem",
          "position": 3,
          "name": "GPT-5 Jailbreak",
          "item": "https://aidarwinawards.org/nominees/gpt5-jailbreak.html"
        }
      ]
    }
  }
  </script>
</head>
<body class="single-nominee">
  <header>
    <h1>GPT-5 Jailbreak</h1>
    <div class="subtitle">AI Darwin Awards</div>
  </header>
  <main>
    <nav aria-label="Breadcrumb">
      <ol class="breadcrumb">
        <li><a href="../index.html">Home</a></li>
        <li><a href="../nominees-2025.html">2025 Nominees</a></li>
        <li><span class="current">GPT-5 Jailbreak</span></li>
      </ol>
    </nav>

    <article>
      <h2>GPT-5 Jailbreak - “One Hour Security Record”</h2>

      <!-- Full nominee content sections go here -->
      <section id="details">
        <div class="nominee-details">
          <div class="actions">
            <button class="share-button" data-share-url="https://aidarwinawards.org/nominees/gpt5-jailbreak.html" title="Share this nominee" aria-label="Share this nominee">
              <img src="../images/share.svg" alt="Share this nominee" />
            </button>
            <span class="verified-badge">Verified</span>
          </div>
          <p class="attribution"><strong>Nominee:</strong> OpenAI Inc. and their AI safety team for deploying GPT-5 with alignment systems that proved vulnerable to academic researchers armed with clever wordplay.</p>
          <p class="attribution"><strong>Reported by:</strong> Dr. Sergey Berezin (NLP Data Scientist) via LinkedIn and published research at ACL 2025 - August 7, 2025.</p>
          <div class="nominee-section"><h3>The Innovation</h3><p>OpenAI launched GPT-5 with great fanfare about enhanced reasoning capabilities and improved safety alignment. The company presumably spent months developing sophisticated safety measures, implementing multiple layers of content filtering and alignment techniques. Their confidence was so high they released the model to the public within hours of announcement.</p></div><div class="nominee-section"><h3>The Academic Catastrophe</h3><p>Just one hour after GPT-5&#39;s release, Dr. Sergey Berezin successfully jailbroke the system using his “Task-in-Prompt” (TIP) attack strategy. This method embeds harmful requests inside seemingly innocent sequential tasks like cipher decoding and riddles. The attack exploits the model&#39;s reasoning capabilities to unknowingly complete harmful requests without ever seeing direct malicious instructions.</p></div><div class="nominee-section"><h3>Why They&#39;re Nominated</h3><p>This represents the perfect storm of AI overconfidence meeting rigorous academic research. OpenAI spent months developing safety measures, then watched as an academic researcher dismantled their defenses in 60 minutes using sophisticated word puzzles. OpenAI managed to create a security system so focused on detecting direct threats that it left itself wide open to the same techniques used to trick children into eating vegetables—just disguise the bad thing as a fun game.</p></div>
          <p><strong>Sources:</strong> <a href="https://www.linkedin.com/posts/s-berezin_llm-aialignment-aisecurity-activity-7359336224513245184-4-Jf" target="_blank" rel="noopener">Sergey Berezin LinkedIn Post</a> | <a href="https://aclanthology.org/2025.acl-long.334/" target="_blank" rel="noopener">ACL 2025 Paper: “The TIP of the Iceberg”</a> | <a href="https://aclanthology.org/2025.acl-long.334/" target="_blank" rel="noopener">PHRYGE Benchmark Research</a></p>
        </div>
      </section>
    </article>
  </main>
  <footer>
    <div class="footer-content">
      <img src="../images/sparkles.svg" alt="AI Darwin Awards Logo" class="footer-logo" loading="lazy">
      <div class="footer-text-group">
        <div class="footer-title">AI Darwin Awards</div>
        <div class="footer-tagline">Guardrails optional</div>
      </div>
      <img src="../images/sparkles.svg" alt="AI Darwin Awards Logo" class="footer-logo" loading="lazy">
    </div>
    <div class="footer">
      &copy; 2025 AI Darwin Awards. No humans or robots were harmed (yet) in the making of this website.
    </div>
  </footer>
  <div id="toast"></div>
</body>
<script src="../js/actions.js" defer></script>
</html>
