<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Submit your AI Darwin Award nominations. Report catastrophically bad AI decisions, spectacular misadventures, and magnificently ill-conceived artificial intelligence deployments.">
    <meta name="keywords" content="AI Darwin Awards nomination, submit AI failure, report AI mistake, AI mishap nomination, worst AI decisions, artificial intelligence disasters">
    <meta name="robots" content="index, follow">
    <meta name="author" content="AI Darwin Awards">
    <meta http-equiv="Content-Security-Policy" content="default-src 'self'; img-src 'self' https:; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline'; object-src 'none'; base-uri 'self'; form-action 'self'; frame-src https://docs.google.com https://www.google.com">

    <link rel="canonical" href="https://aidarwinawards.org/nominate.html">
    <link rel="stylesheet" href="styles/base.css">
    <link rel="stylesheet" href="styles/form.css">
    <title>Nominate an AI Darwin Award Winner - Submit Spectacular AI Failures</title>

    <!-- Open Graph meta tags -->
    <meta property="og:title" content="Nominate an AI Darwin Award Winner - Submit Spectacular AI Failures" />
    <meta property="og:description" content="Submit your AI Darwin Award nominations. Report catastrophically bad AI decisions, spectacular misadventures, and magnificently ill-conceived artificial intelligence deployments." />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://aidarwinawards.org/nominate.html" />
    <meta property="og:site_name" content="AI Darwin Awards" />
    <meta property="og:image" content="https://aidarwinawards.org/images/aidarwinawards-banner.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />
    <meta property="og:image:alt" content="Submit AI Darwin Award nominations - Help us celebrate spectacularly bad AI decisions" />

    <!-- Twitter Cards -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Nominate an AI Darwin Award Winner - Submit Spectacular AI Failures" />
    <meta name="twitter:description" content="Submit your AI Darwin Award nominations. Report catastrophically bad AI decisions, spectacular misadventures, and magnificently ill-conceived artificial intelligence deployments." />
    <meta name="twitter:image" content="https://aidarwinawards.org/images/aidarwinawards-banner.png" />
    <meta name="twitter:image:alt" content="Submit AI Darwin Award nominations - Help us celebrate spectacularly bad AI decisions" />

    <!-- JSON-LD for WebPage structured data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "WebPage",
        "name": "Nominate an AI Darwin Award Winner",
        "description": "Submit your AI Darwin Award nominations. Report catastrophically bad AI decisions, spectacular misadventures, and magnificently ill-conceived artificial intelligence deployments.",
        "url": "https://aidarwinawards.org/nominate.html",
        "isPartOf": {
            "@type": "WebSite",
            "name": "AI Darwin Awards",
            "url": "https://aidarwinawards.org"
        },
        "breadcrumb": {
            "@type": "BreadcrumbList",
            "itemListElement": [
                {
                    "@type": "ListItem",
                    "position": 1,
                    "name": "Home",
                    "item": "https://aidarwinawards.org/"
                },
                {
                    "@type": "ListItem",
                    "position": 2,
                    "name": "Nominate",
                    "item": "https://aidarwinawards.org/nominate.html"
                }
            ]
        }
    }
    </script>
</head>

<body>
    <header>
        <h1>Submit Your Nomination</h1>
        <div class="subtitle">Help Us Celebrate Tomorrow's Cautionary Tales</div>
    </header>
    <main>
        <nav aria-label="Breadcrumb">
            <ol class="breadcrumb">
                <li><a href="index.html">Home</a></li>
                <li><span class="current">Nominate</span></li>
            </ol>
        </nav>

        <section>
            <h2>Know Someone Who Deserves Recognition?</h2>
            <p>
                Welcome to our nomination portal, where your firsthand accounts of AI misadventure become tomorrow's educational content. Whether you've witnessed spectacular corporate overconfidence or experienced the delightful chaos of untested AI deployment, we want to hear from you.
            </p>
            <p>
                Think of this as a public service: by documenting today's magnificently ill-conceived AI decisions, we're creating a valuable resource for future generations who might otherwise repeat these same brilliant mistakes (assuming there are future generations left to learn from them, which given our nominees' track record, is becoming an increasingly optimistic assumption).
            </p>
        </section>

        <section>
            <h2>What We're Looking For</h2>
            <p><em>Your nomination should demonstrate a breathtaking commitment to ignoring obvious risks:</em></p>
            <ul>
                <li><strong>AI Involvement Required:</strong> Must involve cutting-edge artificial intelligence (or what they confidently called "AI" in their investor pitch deck).</li>
                <li><strong>Catastrophic Potential:</strong> The decision must be so magnificently short-sighted that future historians will use it as a cautionary tale (assuming there are any historians left).</li>
                <li><strong>Hubris Bonus Points:</strong> Extra credit for statements like "What's the worst that could happen?" or "The AI knows what it's doing!"</li>
                <li><strong>Ethical Blind Spots:</strong> Demonstrated ability to completely ignore every red flag raised by ethicists, safety researchers, and that one intern who keeps asking uncomfortable questions.</li>
                <li><strong>Scale of Ambition:</strong> Why endanger just yourself when you can endanger everyone? We particularly appreciate nominees who aimed for global impact on their first try.</li>
            </ul>
        </section>

        <section>
            <h2>Popular Nomination Categories</h2>
            <p><em>Based on our extensive research (i.e., scrolling through X - the platform formerly known as Twitter, because apparently everything needs rebranding in the AI era), these are the most common types of AI Darwin Award contenders:</em></p>
            <ul>
                <li><strong>The "AI Will Solve Everything" Executive:</strong> CEOs who replaced entire departments with chatbots, then acted surprised when customer satisfaction scores resembled geological depths.</li>
                <li><strong>The "Move Fast and Break Things" Developer:</strong> Engineers who deployed AI systems to production without testing, because beta testing is for people without vision.</li>
                <li><strong>The "Let's Ask ChatGPT" Professional:</strong> Lawyers, doctors, or other professionals who outsourced their expertise to AI and discovered that artificial intelligence has a very creative relationship with facts.</li>
                <li><strong>The "Efficiency Expert":</strong> Managers who automated critical processes without understanding what those processes actually did, leading to beautifully optimized chaos.</li>
                <li><strong>The "Safety is Optional" Innovator:</strong> Pioneers who viewed AI safety protocols as mere suggestions, preferably ignored in favor of faster deployment schedules.</li>
            </ul>
        </section>

        <section>
            <h2>Nomination Guidelines</h2>
            <p>To help us process your nomination efficiently (and avoid nominating ourselves for an AI Darwin Award), please include:</p>
            <ul>
                <li><strong>Verifiable Details:</strong> News articles, press releases, social media posts, or other publicly available sources. We prefer our catastrophes well-documented.</li>
                <li><strong>Timeline Information:</strong> When did this magnificent disaster unfold? We're particularly interested in 2025 incidents, but exceptional cases from earlier years are welcome.</li>
                <li><strong>Impact Assessment:</strong> How many people were affected? Did it make headlines? Did it require emergency patches? Did anyone have to explain to Congress why their AI was behaving like a caffeinated toddler?</li>
                <li><strong>Quotable Moments:</strong> Any particularly memorable statements from the individuals involved? We love a good "this will revolutionize everything" quote followed by immediate regret.</li>
                <li><strong>Your Connection:</strong> Were you a witness, victim, or just an amused observer? Anonymous submissions are absolutely welcome—we understand that nominating your boss requires discretion.</li>
            </ul>
        </section>

        <section>
            <h2>What Happens Next?</h2>
            <p>
                Once you submit your nomination, our crack team of researchers (and occasionally our AI fact-checking system) will investigate the details. We verify stories through our proprietary blend of actual journalism and asking multiple AI systems whether something sounds plausible.
            </p>
            <p>
                Qualifying nominations will be featured on our website with full attribution to original sources and appropriate credit to news outlets that first reported the story. Winners receive the ultimate prize: eternal recognition for their contribution to humanity's understanding of how <em>not</em> to deploy artificial intelligence.
            </p>
            <p><small><em>Note: We take verification seriously, unlike some of our nominees' approach to AI safety. All stories are checked against reliable sources, and we only feature incidents that actually happened—reality being sufficiently absurd for our purposes.</em></small></p>
        </section>

        <section>
            <h2>Ready to Submit Your Nomination?</h2>
            <p>
                Help us build the definitive archive of AI-related poor decision-making. Your nomination could prevent future disasters by serving as a powerful example of what happens when artificial intelligence meets human overconfidence.
            </p>
            <p>
                Remember: today's catastrophically bad AI decision is tomorrow's AI Darwin Award winner. Together, we can make the future a slightly more careful place—one spectacularly bad deployment at a time!
            </p>
            <p><small><em>Disclaimer: By submitting a nomination, you acknowledge that the future of human civilisation may depend on people learning from these examples. No pressure.</em></small></p>
        </section>

        <div class="form-responsive">
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSe2N_yi1LEelMqWfA6wcmY1l-3_z1KYeMxCexuc6hwIQcs1Uw/viewform?embedded=true" title="AI Darwin Awards Nomination" allowfullscreen>Loading…</iframe>
        </div>
    </main>
    <footer>
        <div class="footer-content">
            <img src="images/sparkles.svg" alt="AI Darwin Awards Logo" class="footer-logo" loading="lazy">
            <div class="footer-text-group">
                <div class="footer-title">AI Darwin Awards</div>
                <div class="footer-tagline">Preserving Poor Decisions for Posterity</div>
            </div>
            <img src="images/sparkles.svg" alt="AI Darwin Awards Logo" class="footer-logo" loading="lazy">
        </div>
        <div class="footer">
            &copy; 2025 AI Darwin Awards. No humans or robots were harmed (yet) in the making of this website.
        </div>
    </footer>
</body>

</html>
