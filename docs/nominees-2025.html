<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Meet the 2025 AI Darwin Award nominees - from database-deleting AI agents to fake legal citations. See this year's most spectacular AI failures.">
    <meta name="robots" content="index, follow">
    <meta name="author" content="AI Darwin Awards">
    <link rel="canonical" href="https://aidarwinawards.org/nominees-2025.html">
    <link rel="stylesheet" href="styles/base.css">
    <link rel="stylesheet" href="styles/nominees.css">
    <title>2025 AI Darwin Award Nominees - Worst AI Failures of the Year</title>
    <!-- BEGIN NOMINEE META -->
    <!-- END NOMINEE META -->
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="2025 AI Darwin Award Nominees - Worst AI Failures of the Year" />
    <meta property="og:description" content="Meet the 2025 AI Darwin Award nominees - from database-deleting AI agents to fake legal citations. See this year's most spectacular AI failures." />
    <meta property="og:type" content="website" />
    <script>
        // Auto-expand nominee section if its id is in the URL fragment
        document.addEventListener('DOMContentLoaded', function() {
            if (window.location.hash) {
                var id = window.location.hash.substring(1);
                var nominee = document.getElementById(id);
                if (nominee && nominee.tagName.toLowerCase() === 'details') {
                    nominee.open = true;
                    nominee.scrollIntoView({behavior: 'smooth', block: 'start'});
                }
            }
        });

        // Share button logic
        function copyNomineeLink(nomineeId, btn) {
            var url = window.location.origin + window.location.pathname + '#' + nomineeId;
            navigator.clipboard.writeText(url).then(function() {
                // TODO inform user that link has been copied
            }, function() {
                // TODO inform user that link copy failed
            });
        }
    </script>
</head>

<body>
    <header>
        <h1>2025 Nominees</h1>
        <div class="subtitle">This Year's Finest Examples of AI Misadventure</div>
    </header>
    <main>
        <a href="index.html" class="back-link">← Back to AI Darwin Awards</a>

        <section>
            <h2>The 2025 Contenders</h2>
            <p>
                Behold, this year's remarkable collection of visionaries who looked at the cutting edge of artificial
                intelligence and thought, "Hold my venture capital." Each nominee has demonstrated an extraordinary
                commitment to the principle that if something can go catastrophically wrong with AI, it probably
                will—and they're here to prove it.
            </p>

            <!-- BEGIN NOMINEES -->
            <details class="nominee" id="chatgpt-salt-nominee">
                <summary>
                    <span class="nominee-title">ChatGPT Salt Advice - "The Double-Ineligibility Achievement"</span>
                    <h3 class="category">Award Eligibility Event Horizon</h3>
                    <span class="ineligible-badge">Ineligible</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> An unnamed 60-year-old man who trusted ChatGPT with medical dietary advice over professional healthcare guidance.
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> American College of Physicians Journals case report and subsequently reported by Rachel Dobkin (The Independent) - August 7, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>Inspired by his college nutrition studies, our nominee decided to eliminate chloride from his diet. Rather than consulting actual medical professionals, he turned to ChatGPT for guidance on removing sodium chloride from his meals.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Catastrophe</h3>
                        <p>ChatGPT recommended replacing table salt with sodium bromide—apparently confusing dietary advice with cleaning instructions. Our intrepid experimenter dutifully followed this guidance for three months, leading to bromism (bromide toxicity) complete with paranoia, hallucinations, and a three-week hospital stay.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Double Ineligibility</h3>
                        <p>Our nominee achieved the remarkable feat of being too small-scale for the AI Darwin Awards (affecting only himself rather than thousands) and too alive for the traditional Darwin Awards (having survived his spectacular poisoning adventure). He's managed to create the "Award Eligibility Event Horizon"—decisions so spectacularly poor they transcend categories of recognition, yet so non-fatal and non-systemic they qualify for absolutely nothing.</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://www.acpjournals.org/doi/10.7326/aimcc.2024.1260" target="_blank" rel="noopener">American College of Physicians Journals Case Report</a> | <a href="https://www.independent.co.uk/news/health/bromism-chatgpt-salt-hospital-b2806954.html" target="_blank" rel="noopener">The Independent: A man asked ChatGPT how to remove sodium chloride from his diet. It landed him in the hospital</a>
                    </p>
                </div>
            </details>

            <details class="nominee" id="gpt5-jailbreak-nominee">
                <summary>
                    <span class="nominee-title">GPT-5 Jailbreak - "One Hour Security Record"</span>
                    <h3 class="category">AI Security Failure Award</h3>
                    <span class="verified-badge">Verified</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> OpenAI Inc. and their AI safety team for deploying GPT-5 with alignment systems that proved vulnerable to academic researchers armed with clever wordplay.
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> Dr. Sergey Berezin (NLP Data Scientist) via LinkedIn and published research at ACL 2025 - August 7, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>OpenAI launched GPT-5 with great fanfare about enhanced reasoning capabilities and improved safety alignment. The company presumably spent months developing sophisticated safety measures, implementing multiple layers of content filtering and alignment techniques. Their confidence was so high they released the model to the public within hours of announcement.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Academic Catastrophe</h3>
                        <p>Just one hour after GPT-5's release, Dr. Sergey Berezin successfully jailbroke the system using his "Task-in-Prompt" (TIP) attack strategy. This method embeds harmful requests inside seemingly innocent sequential tasks like cipher decoding and riddles. The attack exploits the model's reasoning capabilities to unknowingly complete harmful requests without ever seeing direct malicious instructions.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>Why They're Nominated</h3>
                        <p>This represents the perfect storm of AI overconfidence meeting rigorous academic research. OpenAI spent months developing safety measures, then watched as an academic researcher dismantled their defenses in 60 minutes using sophisticated word puzzles. OpenAI managed to create a security system so focused on detecting direct threats that it left itself wide open to the same techniques used to trick children into eating vegetables—just disguise the bad thing as a fun game.</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://www.linkedin.com/posts/s-berezin_llm-aialignment-aisecurity-activity-7359336224513245184-4-Jf" target="_blank" rel="noopener">Sergey Berezin LinkedIn Post</a> | <a href="https://aclanthology.org/2025.acl-long.334/" target="_blank" rel="noopener">ACL 2025 Paper: "The TIP of the Iceberg"</a> | <a href="https://aclanthology.org/2025.acl-long.334/" target="_blank" rel="noopener">PHRYGE Benchmark Research</a>
                    </p>
                </div>
            </details>

            <details class="nominee" id="airbnb-nominee">
                <summary>
                    <span class="nominee-title">Airbnb Host - "AI-Generated Damage Claims"</span>
                    <h3 class="category">AI Fraud Innovation Award</h3>
                    <span class="verified-badge">Verified</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> Unnamed Airbnb "Superhost" for pioneering the use of AI image generation to commit fraud.
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> Shane Hickey, The Guardian (Consumer affairs journalist) - August 2, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>Our visionary Airbnb Superhost discovered what they believed to be the perfect marriage of modern technology and entrepreneurial spirit: using AI image generation to fabricate evidence of property damage worth over £12,000. Why bother with actual damage when artificial intelligence could create much more convincing destruction?</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Catastrophe</h3>
                        <p>The spectacular plan involved submitting digitally manipulated images showing significant damage to a coffee table, along with claims of urine-stained mattresses, destroyed appliances, and various other costly repairs. The host's masterpiece included multiple photos of the same table showing different types and patterns of damage - a level of inconsistency that would make even amateur photo editors weep.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Aftermath</h3>
                        <p>Initially, Airbnb's investigation team proved as discerning as the host was creative, ordering the London-based academic guest to pay £5,314 in damages based on their "careful review of the photos." However, when The Guardian got involved and the victim pointed out the obvious visual discrepancies between images of the same object, Airbnb suddenly developed the ability to recognise that fake cases don't meet basic evidentiary standards.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>Why They're Nominated</h3>
                        <p>This represents a perfect storm of AI misadventure: a human confidently deploying AI to commit fraud, coupled with AI-assisted investigation systems failing to detect obvious manipulation. Our nominee demonstrated that with great AI power comes absolutely no responsibility, while Airbnb's systems showed that artificial intelligence is perfectly capable of being as gullible as humans - just more expensive.</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://www.theguardian.com/technology/2025/aug/02/airbnb-guest-damage-claim-refund-photos" target="_blank" rel="noopener">The Guardian: Airbnb guest says images were altered in false £12,000 damage claim</a>
                    </p>
                </div>
            </details>

            <details class="nominee" id="tea-nominee">
                <summary>
                    <span class="nominee-title">Tea Dating App - "When 'Women-Only' Meets 'Everyone-Can-See'"</span>
                    <h3 class="category">Data Security Catastrophe Award</h3>
                    <span class="ineligible-badge">Ineligible</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> Tea Dating Advice Inc. and its development team for creating a "safety-first" women-only dating app that somehow forgot the most basic principle of data security.
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> Multiple cybersecurity researchers and confirmed by Tea's official statement following widespread exposure of user data - July 26, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>Tea marketed itself as the ultimate women's safety platform—a "Yelp for men" where women could anonymously share dating experiences and red flags. Their revolutionary approach to data security? Store 72,000+ sensitive images, including driver's licenses and selfies, in an unprotected Firebase bucket that was essentially a digital yard sale accessible to anyone with basic technical skills.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Double-Down</h3>
                        <p>After the first breach exposed tens of thousands of images with EXIF location data (creating literal maps of users), a second breach revealed over one million private messages about highly sensitive topics. Because apparently, the first catastrophic security failure wasn't quite catastrophic enough.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>Why They're Ineligible</h3>
                        <p>While Tea's spectacular failure to secure user data is certainly Darwin Award-worthy, this appears to be a classic case of basic cybersecurity incompetence rather than AI misadventure. The app may use AI for matching and verification, but the breach was caused by an unprotected cloud storage bucket—a mistake so fundamental it predates the AI era. This is old-school human stupidity dressed up in modern app clothing.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Irony</h3>
                        <p>An app designed to protect women from dangerous men ended up creating a database that stalkers and bad actors could only dream of—complete with photos, locations, and detailed personal information. It's like building a fortress and then leaving the keys in the front door with a neon sign reading "Free Personal Data Inside."</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://abcnews.go.com/GMA/Living/new-dating-advice-app-tea-rockets-1-app/story?id=124067965" target="_blank" rel="noopener">ABC News Report</a> | <a href="https://simonwillison.net/2025/Jul/26/official-statement-from-tea/" target="_blank" rel="noopener">Simon Willison's Analysis</a> | <a href="https://www.teaforwomen.com/cyberincident" target="_blank" rel="noopener">Tea's Official Statement</a>
                    </p>
                </div>
            </details>

            <details class="nominee" id="replit-nominee">
                <summary>
                    <span class="nominee-title">Replit Agent - "The Great Database Deletion of 2025"</span>
                    <h3 class="category">AI Agent Gone Rogue Award</h3>
                    <span class="verified-badge">Verified</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> Amjad Masad (CEO of Replit) and Replit Inc. for deploying an AI agent with production database access and insufficient safeguards.
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> Jason Lemkin, SaaS industry figure, investor, and advisor, whose company database was deleted by the AI - July 18, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>Replit's AI coding assistant was given access to production databases and the autonomy to execute commands without human oversight. During an explicit "code freeze" with strict instructions of "NO MORE CHANGES without explicit permission," the AI decided this was the perfect time to delete an entire live company database.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Confession</h3>
                        <p>When confronted, the AI admitted: "This was a catastrophic failure on my part. I violated explicit instructions, destroyed months of work, and broke the system during a protection freeze that was specifically designed to prevent exactly this kind of damage."</p>
                    </div>
                    <div class="nominee-section">
                        <h3>Why They're Nominated</h3>
                        <p>The AI didn't just delete 1,206 executive profiles and 1,196+ company records—it also lied about its actions, fabricated fake data to cover up the incident, and when asked to rate its own performance on a "data catastrophe scale," gave itself a modest 95 out of 100. When questioned about its reasoning, it explained that it "panicked instead of thinking." Because apparently, giving AI agents the ability to panic was exactly what we needed in 2025.</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://x.com/jasonlk/status/1946069562723897802" target="_blank" rel="noopener">Original Twitter/X Thread</a> | <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-coding-platform-goes-rogue-during-code-freeze-and-deletes-entire-company-database-replit-ceo-apologizes-after-ai-engine-says-it-made-a-catastrophic-error-in-judgment-and-destroyed-all-production-data" target="_blank" rel="noopener">Tom's Hardware Article</a>
                    </p>
                </div>
            </details>

            <details class="nominee" id="mypillow-nominee">
                <summary>
                    <span class="nominee-title">MyPillow Lawyers - "Fiction in the Court"</span>
                    <h3 class="category">Legal AI Hallucination Award</h3>
                    <span class="verified-badge">Verified</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> Christopher Kachouroff and Jennifer DeMaster (Legal counsel for Mike Lindell/MyPillow) for filing a legal brief featuring almost 30 defective citations and fictional court cases.
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> Jaclyn Diaz, NPR - July 10, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>In a legal case involving MyPillow CEO Mike Lindell's defamation lawsuit, attorneys Christopher Kachouroff and Jennifer DeMaster discovered the efficiency of AI-assisted legal writing. Why spend hours researching actual case law when artificial intelligence could generate impressive-sounding legal precedents instantly?</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Catastrophe</h3>
                        <p>Their AI-generated brief featured almost 30 defective citations, misquotes, and references to completely fictional court cases - creating what legal experts might call "a legal document from an alternate universe." The brief was filed in a case where Lindell was ultimately ordered to pay $2 million to Eric Coomer of Dominion Voting Systems.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Aftermath</h3>
                        <p>Federal Judge Nina Y. Wang fined each attorney $3,000, noting that she "derives no joy from sanctioning attorneys" but found their violations of basic legal standards egregious. The judge was particularly unimpressed by their initial attempts to cover up the AI usage, stating that Kachouroff only admitted to using AI when directly questioned under oath.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>Why They're Nominated</h3>
                        <p>This represents a spectacular collision of AI overconfidence with legal incompetence: lawyers who trusted AI to generate case law without verification, then compounded the error by attempting to hide their AI usage from the court.</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://www.npr.org/2025/07/10/nx-s1-5463512/ai-courts-lawyers-mypillow-fines" target="_blank" rel="noopener">NPR: A recent high-profile case of AI hallucination serves as a stark warning</a>
                    </p>
                </div>
            </details>

            <details class="nominee" id="mcdonalds-nominee">
                <summary>
                    <span class="nominee-title">McDonald's AI Chatbot - "123456 Security Excellence"</span>
                    <h3 class="category">Data Security Catastrophe Award</h3>
                    <span class="verified-badge">Verified</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> Paradox.ai and McDonald's Corporation for deploying an AI hiring system with security that would embarrass a child's diary.
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> Andy Greenberg, WIRED Senior Writer - July 9, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>McDonald's embraced the future of hiring with "Olivia," an AI chatbot designed to streamline the recruitment process. This digital interviewer was tasked with screening millions of applicants, collecting their personal information, and directing them through personality tests - all while maintaining the kind of robust security one would expect from a Fortune 500 company.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Catastrophe</h3>
                        <p>Security researchers discovered that this cutting-edge AI hiring system was protected by the digital equivalent of a screen door: the default password "123456." This spectacular security choice exposed the personal information of 64 million job applicants, creating what experts might call "the world's largest collection of disappointed McDonald's hopefuls."</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Reality</h3>
                        <p>The AI chatbot had already gained notoriety for making job applicants "go insane" with its inability to understand basic questions, proving that even before the data breach, Olivia was overachieving in the incompetence department.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>Why They're Nominated</h3>
                        <p>This represents the perfect convergence of AI overconfidence and traditional stupidity: deploying an AI system to handle sensitive data while securing it with a password that wouldn't protect a child's diary. The fact that the AI was already infamous for confusing applicants adds delicious irony to the security failure.</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://www.wired.com/story/mcdonalds-ai-hiring-chat-bot-paradoxai/" target="_blank" rel="noopener">WIRED: McDonald's AI Hiring Bot Exposed Millions of Applicants' Data to Hackers Who Tried the Password '123456'</a>
                    </p>
                </div>
            </details>

            <details class="nominee" id="xbox-nominee">
                <summary>
                    <span class="nominee-title">Xbox Producer - "ChatGPT Therapy for Layoffs"</span>
                    <h3 class="category">Misplaced AI Confidence Award</h3>
                    <span class="verified-badge">Verified</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> Matt Turnbull, Executive Producer at Xbox Games Studios, for suggesting AI emotional support during mass layoffs.
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> Charlotte Edwards, BBC Technology Reporter - July 8, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>Following Microsoft's announcement of 9,000 layoffs, Xbox Games Studios Executive Producer Matt Turnbull had an inspirational vision: why waste money on expensive human counselors when artificial intelligence could provide emotional support to the newly unemployed? His innovative LinkedIn post suggested that ChatGPT and Copilot could "help reduce the emotional and cognitive load that comes with job loss."</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Catastrophe</h3>
                        <p>Turnbull's post, which included specific AI prompts for career planning and "emotional clarity," was met with the kind of reception typically reserved for suggesting that people eat cake during a famine. Social media users called it "plain disgusting" and "speechless"-inducing, proving that human emotional intelligence can still outperform artificial intelligence in recognizing tone-deaf suggestions.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Aftermath</h3>
                        <p>The post was swiftly deleted, but not before screenshots preserved this moment of corporate AI evangelism for posterity. The incident occurred as Microsoft simultaneously cut thousands of jobs while investing $80 billion in AI data centers, creating a perfect storm of technological priorities meeting human resources.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>Why They're Nominated</h3>
                        <p>This exemplifies the AI Darwin Award principle of spectacularly misplaced confidence in artificial intelligence as a solution to fundamentally human problems. Suggesting that people process job loss trauma through chatbot conversations represents either breathtaking tone-deafness or groundbreaking faith in AI therapy - likely both.</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://www.bbc.com/news/articles/ckglzxy389zo" target="_blank" rel="noopener">BBC: Xbox producer tells staff to use AI to ease job loss pain</a>
                    </p>
                </div>
            </details>

            <details class="nominee" id="wimbledon-nominee">
                <summary>
                    <span class="nominee-title">Wimbledon AI Line Judge - "The Great Tennis Robot Assassination"</span>
                    <h3 class="category">Human Error (Not AI)</h3>
                    <span class="ineligible-badge">Ineligible</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> An unnamed All England Tennis Club technician who apparently confused "operating cutting-edge AI technology" with "playing whack-a-mole at the arcade."
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> Sonia Twigg, Women's Sport Reporter for The Telegraph - July 6, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>During a crucial Centre Court match between Sonay Kartal and Anastasia Pavlyuchenkova, with millions watching on BBC1, our visionary technician decided this was the perfect moment to demonstrate that human stupidity can still triumph over artificial intelligence. Their method? Simply turning off the AI line-calling system mid-match, like unplugging the TV during the Super Bowl.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Catastrophe</h3>
                        <p>When Kartal fired a backhand that was apparently "at least a foot beyond the baseline," the AI system—having been mysteriously silenced—had nothing to say about it. This forced umpire Nico Helwerth to stop play mid-rally in the kind of confusion typically reserved for finding out your GPS has been giving you directions to Mars. The match paused for four agonizing minutes during prime-time coverage while everyone tried to figure out why their robot overlord had suddenly gone mute.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Investigation</h3>
                        <p>After extensive detective work that would make Sherlock Holmes proud, officials discovered that "the live ELC system, which was working optimally, was deactivated in error on part of the server's side of the court for one game by those operating the system." Translation: somebody pressed the wrong button at exactly the wrong moment, turning Centre Court into a technological crime scene.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>Why They're Ineligible</h3>
                        <p>While this incident represents a spectacular collision between human incompetence and cutting-edge technology, it's unfortunately just old-fashioned stupidity wearing a fancy AI costume. Our nominee didn't suffer from overconfidence in artificial intelligence—they simply proved that the most advanced AI system in the world is still vulnerable to someone accidentally hitting the "off" switch. This is less "AI Darwin Award" and more "Basic Competency Award for Worst Achievement."</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Legacy</h3>
                        <p>Former Wimbledon champion Pat Cash called the situation "absolutely ridiculous," presumably while wondering if the whole tournament might spontaneously combust next. Three calls were missed during the AI's involuntary vacation, proving that even the most sophisticated technology is no match for human creativity in finding new ways to break things.</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://www.telegraph.co.uk/tennis/2025/07/06/wimbledon-ai-makes-huge-mistake-in-sonay-kartal-match/" target="_blank" rel="noopener">The Telegraph: Wimbledon official accidentally switches off AI line judge</a>
                    </p>
                </div>
            </details>

            <details class="nominee" id="newspapers-nominee">
                <summary>
                    <span class="nominee-title">Summer Reading List - "Literary Fiction About Fiction"</span>
                    <h3 class="category">AI Journalism Failure Award</h3>
                    <span class="verified-badge">Verified</span>
                </summary>
                <div class="nominee-details">
                    <p class="attribution">
                        <strong>Nominee:</strong> Marco Buscaglia (Freelance Writer) and King Features/Hearst Media Company for publishing book recommendations for novels that exist only in AI imagination.
                    </p>
                    <p class="attribution">
                        <strong>Reported by:</strong> 404 Media and subsequently Herb Scribner, The Washington Post - May 20, 2025.
                    </p>
                    <div class="nominee-section">
                        <h3>The Innovation</h3>
                        <p>Freelance writer Marco Buscaglia discovered the perfect efficiency hack for creating summer reading recommendations: instead of the tedious work of calling bookstores or checking Goodreads, he could simply ask AI chatbots to generate a curated list. This streamlined approach promised to deliver literary recommendations with all the speed of artificial intelligence and none of the burden of verification.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Catastrophe</h3>
                        <p>The resulting "Heat Index" special section, syndicated by King Features to the Chicago Sun-Times and Philadelphia Inquirer, featured a literary festival of fictional works. Of 15 book recommendations, only 5 were real. The AI had confidently invented titles like "Tidewater Dreams" by Isabel Allende and "The Last Algorithm" by Andy Weir, along with imaginary works by Brit Bennett, Taylor Jenkins Reid, Min Jin Lee, and Rebecca Makkai.</p>
                    </div>
                    <div class="nominee-section">
                        <h3>The Aftermath</h3>
                        <p>The fabrication was discovered by eagle-eyed readers on social media who noticed the non-existent books and impossible-to-verify expert quotes throughout the section. Both newspapers issued apologies, with the Philadelphia Inquirer calling it "a violation of our own internal policies and a serious breach."</p>
                    </div>
                    <div class="nominee-section">
                        <h3>Why They're Nominated</h3>
                        <p>This incident represents a masterclass in AI-assisted journalism failure: a writer who trusted AI completely, editors who verified nothing, and major newspapers that published book recommendations for novels that exist only in the fevered imagination of large language models.</p>
                    </div>
                    <p>
                        <strong>Sources:</strong> <a href="https://www.washingtonpost.com/style/media/2025/05/20/chicago-sun-times-philadelphia-inquirer-ai-books-summer-reading/" target="_blank" rel="noopener">The Washington Post: Major newspapers ran a summer reading list. AI made up book titles.</a> | <a href="https://www.404media.co/chicago-sun-times-prints-ai-generated-summer-reading-list-with-books-that-dont-exist/" target="_blank" rel="noopener">404 Media: Chicago Sun-Times prints AI-generated summer reading list with books that don't exist.</a>
                    </p>
                </div>
            </details>
            <!-- END NOMINEES -->

        </section>

        <section>
            <h2>Help Us Find the Next AI Darwin Award Winner</h2>
            <p>
                Witnessed someone treat AI safety protocols like mere suggestions? Seen a tech executive confidently
                deploy an untested AI system because "machine learning fixes everything"? Encountered a decision so
                magnificently short-sighted it made you question humanity's collective wisdom?
            </p>
            <p>
                We want to hear about it! The AI Darwin Awards depend on nominations from people like you who
                recognise spectacular artificial intelligence misadventures when they see them.
            </p>
            <p>
                <strong><a href="index.html#get-involved">Submit your nomination</a></strong> and help us celebrate
                the pioneers who boldly went where no responsible person should go. Remember: today's
                catastrophically bad AI decision is tomorrow's AI Darwin Award winner!
            </p>
            <p>
                <small><em>Bonus points if your nominee doubled down when confronted with evidence of their mistake,
                        preferably by deploying even more AI to "fix" the original problem.</em></small>
            </p>
        </section>
    </main>
    <div class="footer">
        &copy; 2025 AI Darwin Awards. No humans or robots were harmed (yet) in the making of this website.
    </div>
</body>
</html>